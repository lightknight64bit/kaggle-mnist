{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.7 64-bit"
  },
  "interpreter": {
   "hash": "cc313781c8b16b1a20b25b0369e14de97ee7f97b5a7f722f22de07301d7c790b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnistdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file, transform=None):\n",
    "\n",
    "        self.file = pd.read_csv(file)\n",
    "        self.labels = self.file[\"label\"].values\n",
    "        self.transform = transform  \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.file.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        im = self.file.iloc[idx, 1:].to_numpy(dtype=\"uint8\").reshape(-1)\n",
    "        im = np.array([im]).reshape(28,28)\n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "        return im, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(),transforms.Normalize((0.1307), (0.3081))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mnistdataset(\"train.csv\", transform = train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 5, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 5, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.m1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.d1 = nn.Dropout2d(0.25)\n",
    "        self.conv3 = nn.Conv2d(64,64,3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64,64,3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.m2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.d2 = nn.Dropout2d(0.25)\n",
    "        self.conv6 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.d3 = nn.Dropout2d(0.25)\n",
    "        self.lin1 = nn.Linear(4608, 400)\n",
    "        self.d4 = nn.Dropout(0.4)\n",
    "        self.lin2 = nn.Linear(400, 28)\n",
    "        self.d5 = nn.Dropout(0.2)\n",
    "        self.lin3 = nn.Linear(28, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.m1(x)\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.bn5(x)\n",
    "        x = self.m2(x)\n",
    "        x = self.d2(x)\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.bn6(x)\n",
    "        x = self.d3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.d2(x)\n",
    "        x = self.lin3(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().cuda()\n",
    "opt = optim.SGD(net.parameters(), lr= 0.01, momentum=0.5)\n",
    "loss = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 0 [1600/42000 (4%)]\tLoss: 0.576881\n",
      "Train Epoch: 0 [3200/42000 (8%)]\tLoss: 0.170274\n",
      "Train Epoch: 0 [4800/42000 (11%)]\tLoss: 0.078572\n",
      "Train Epoch: 0 [6400/42000 (15%)]\tLoss: 0.062531\n",
      "Train Epoch: 0 [8000/42000 (19%)]\tLoss: 0.017799\n",
      "Train Epoch: 0 [9600/42000 (23%)]\tLoss: 0.118225\n",
      "Train Epoch: 0 [11200/42000 (27%)]\tLoss: 0.017775\n",
      "Train Epoch: 0 [12800/42000 (30%)]\tLoss: 0.017476\n",
      "Train Epoch: 0 [14400/42000 (34%)]\tLoss: 0.028269\n",
      "Train Epoch: 0 [16000/42000 (38%)]\tLoss: 0.021743\n",
      "Train Epoch: 0 [17600/42000 (42%)]\tLoss: 0.097567\n",
      "Train Epoch: 0 [19200/42000 (46%)]\tLoss: 0.245781\n",
      "Train Epoch: 0 [20800/42000 (50%)]\tLoss: 0.076020\n",
      "Train Epoch: 0 [22400/42000 (53%)]\tLoss: 0.015823\n",
      "Train Epoch: 0 [24000/42000 (57%)]\tLoss: 0.012150\n",
      "Train Epoch: 0 [25600/42000 (61%)]\tLoss: 0.028204\n",
      "Train Epoch: 0 [27200/42000 (65%)]\tLoss: 0.182551\n",
      "Train Epoch: 0 [28800/42000 (69%)]\tLoss: 0.006621\n",
      "Train Epoch: 0 [30400/42000 (72%)]\tLoss: 0.057527\n",
      "Train Epoch: 0 [32000/42000 (76%)]\tLoss: 0.002620\n",
      "Train Epoch: 0 [33600/42000 (80%)]\tLoss: 0.022599\n",
      "Train Epoch: 0 [35200/42000 (84%)]\tLoss: 0.121090\n",
      "Train Epoch: 0 [36800/42000 (88%)]\tLoss: 0.457967\n",
      "Train Epoch: 0 [38400/42000 (91%)]\tLoss: 0.063493\n",
      "Train Epoch: 0 [40000/42000 (95%)]\tLoss: 0.116134\n",
      "Train Epoch: 0 [41600/42000 (99%)]\tLoss: 0.050000\n",
      "Train Epoch: 1 [1600/42000 (4%)]\tLoss: 0.235125\n",
      "Train Epoch: 1 [3200/42000 (8%)]\tLoss: 0.000788\n",
      "Train Epoch: 1 [4800/42000 (11%)]\tLoss: 0.006100\n",
      "Train Epoch: 1 [6400/42000 (15%)]\tLoss: 0.017250\n",
      "Train Epoch: 1 [8000/42000 (19%)]\tLoss: 0.000983\n",
      "Train Epoch: 1 [9600/42000 (23%)]\tLoss: 0.006227\n",
      "Train Epoch: 1 [11200/42000 (27%)]\tLoss: 0.026180\n",
      "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 0.082108\n",
      "Train Epoch: 1 [14400/42000 (34%)]\tLoss: 0.001861\n",
      "Train Epoch: 1 [16000/42000 (38%)]\tLoss: 0.038380\n",
      "Train Epoch: 1 [17600/42000 (42%)]\tLoss: 0.010321\n",
      "Train Epoch: 1 [19200/42000 (46%)]\tLoss: 0.239232\n",
      "Train Epoch: 1 [20800/42000 (50%)]\tLoss: 0.002239\n",
      "Train Epoch: 1 [22400/42000 (53%)]\tLoss: 0.035972\n",
      "Train Epoch: 1 [24000/42000 (57%)]\tLoss: 0.028055\n",
      "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 0.004406\n",
      "Train Epoch: 1 [27200/42000 (65%)]\tLoss: 0.001158\n",
      "Train Epoch: 1 [28800/42000 (69%)]\tLoss: 0.031496\n",
      "Train Epoch: 1 [30400/42000 (72%)]\tLoss: 0.000244\n",
      "Train Epoch: 1 [32000/42000 (76%)]\tLoss: 0.000879\n",
      "Train Epoch: 1 [33600/42000 (80%)]\tLoss: 0.002247\n",
      "Train Epoch: 1 [35200/42000 (84%)]\tLoss: 0.067120\n",
      "Train Epoch: 1 [36800/42000 (88%)]\tLoss: 0.558048\n",
      "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 0.005044\n",
      "Train Epoch: 1 [40000/42000 (95%)]\tLoss: 0.000766\n",
      "Train Epoch: 1 [41600/42000 (99%)]\tLoss: 0.010248\n",
      "Train Epoch: 2 [1600/42000 (4%)]\tLoss: 0.004139\n",
      "Train Epoch: 2 [3200/42000 (8%)]\tLoss: 0.016276\n",
      "Train Epoch: 2 [4800/42000 (11%)]\tLoss: 0.007325\n",
      "Train Epoch: 2 [6400/42000 (15%)]\tLoss: 0.008049\n",
      "Train Epoch: 2 [8000/42000 (19%)]\tLoss: 0.061604\n",
      "Train Epoch: 2 [9600/42000 (23%)]\tLoss: 0.000429\n",
      "Train Epoch: 2 [11200/42000 (27%)]\tLoss: 0.001164\n",
      "Train Epoch: 2 [12800/42000 (30%)]\tLoss: 0.021930\n",
      "Train Epoch: 2 [14400/42000 (34%)]\tLoss: 0.000795\n",
      "Train Epoch: 2 [16000/42000 (38%)]\tLoss: 0.001209\n",
      "Train Epoch: 2 [17600/42000 (42%)]\tLoss: 0.002439\n",
      "Train Epoch: 2 [19200/42000 (46%)]\tLoss: 0.015170\n",
      "Train Epoch: 2 [20800/42000 (50%)]\tLoss: 0.039594\n",
      "Train Epoch: 2 [22400/42000 (53%)]\tLoss: 0.006101\n",
      "Train Epoch: 2 [24000/42000 (57%)]\tLoss: 0.002795\n",
      "Train Epoch: 2 [25600/42000 (61%)]\tLoss: 0.003700\n",
      "Train Epoch: 2 [27200/42000 (65%)]\tLoss: 0.000930\n",
      "Train Epoch: 2 [28800/42000 (69%)]\tLoss: 0.153049\n",
      "Train Epoch: 2 [30400/42000 (72%)]\tLoss: 0.002834\n",
      "Train Epoch: 2 [32000/42000 (76%)]\tLoss: 0.200213\n",
      "Train Epoch: 2 [33600/42000 (80%)]\tLoss: 0.026818\n",
      "Train Epoch: 2 [35200/42000 (84%)]\tLoss: 0.072383\n",
      "Train Epoch: 2 [36800/42000 (88%)]\tLoss: 0.004160\n",
      "Train Epoch: 2 [38400/42000 (91%)]\tLoss: 0.011701\n",
      "Train Epoch: 2 [40000/42000 (95%)]\tLoss: 0.000666\n",
      "Train Epoch: 2 [41600/42000 (99%)]\tLoss: 0.013039\n",
      "Train Epoch: 3 [1600/42000 (4%)]\tLoss: 0.023649\n",
      "Train Epoch: 3 [3200/42000 (8%)]\tLoss: 0.276040\n",
      "Train Epoch: 3 [4800/42000 (11%)]\tLoss: 0.147241\n",
      "Train Epoch: 3 [6400/42000 (15%)]\tLoss: 0.003057\n",
      "Train Epoch: 3 [8000/42000 (19%)]\tLoss: 0.004604\n",
      "Train Epoch: 3 [9600/42000 (23%)]\tLoss: 0.022441\n",
      "Train Epoch: 3 [11200/42000 (27%)]\tLoss: 0.019751\n",
      "Train Epoch: 3 [12800/42000 (30%)]\tLoss: 0.347306\n",
      "Train Epoch: 3 [14400/42000 (34%)]\tLoss: 0.000407\n",
      "Train Epoch: 3 [16000/42000 (38%)]\tLoss: 0.003338\n",
      "Train Epoch: 3 [17600/42000 (42%)]\tLoss: 0.038065\n",
      "Train Epoch: 3 [19200/42000 (46%)]\tLoss: 0.096966\n",
      "Train Epoch: 3 [20800/42000 (50%)]\tLoss: 0.007758\n",
      "Train Epoch: 3 [22400/42000 (53%)]\tLoss: 0.000810\n",
      "Train Epoch: 3 [24000/42000 (57%)]\tLoss: 0.009482\n",
      "Train Epoch: 3 [25600/42000 (61%)]\tLoss: 0.003212\n",
      "Train Epoch: 3 [27200/42000 (65%)]\tLoss: 0.003286\n",
      "Train Epoch: 3 [28800/42000 (69%)]\tLoss: 0.001224\n",
      "Train Epoch: 3 [30400/42000 (72%)]\tLoss: 0.002101\n",
      "Train Epoch: 3 [32000/42000 (76%)]\tLoss: 0.038531\n",
      "Train Epoch: 3 [33600/42000 (80%)]\tLoss: 0.094964\n",
      "Train Epoch: 3 [35200/42000 (84%)]\tLoss: 0.006352\n",
      "Train Epoch: 3 [36800/42000 (88%)]\tLoss: 0.002845\n",
      "Train Epoch: 3 [38400/42000 (91%)]\tLoss: 0.000877\n",
      "Train Epoch: 3 [40000/42000 (95%)]\tLoss: 0.000109\n",
      "Train Epoch: 3 [41600/42000 (99%)]\tLoss: 0.001455\n",
      "Train Epoch: 4 [1600/42000 (4%)]\tLoss: 0.000890\n",
      "Train Epoch: 4 [3200/42000 (8%)]\tLoss: 0.021894\n",
      "Train Epoch: 4 [4800/42000 (11%)]\tLoss: 0.040686\n",
      "Train Epoch: 4 [6400/42000 (15%)]\tLoss: 0.201907\n",
      "Train Epoch: 4 [8000/42000 (19%)]\tLoss: 0.014419\n",
      "Train Epoch: 4 [9600/42000 (23%)]\tLoss: 0.003573\n",
      "Train Epoch: 4 [11200/42000 (27%)]\tLoss: 0.002949\n",
      "Train Epoch: 4 [12800/42000 (30%)]\tLoss: 0.001526\n",
      "Train Epoch: 4 [14400/42000 (34%)]\tLoss: 0.000510\n",
      "Train Epoch: 4 [16000/42000 (38%)]\tLoss: 0.124449\n",
      "Train Epoch: 4 [17600/42000 (42%)]\tLoss: 0.000139\n",
      "Train Epoch: 4 [19200/42000 (46%)]\tLoss: 0.051841\n",
      "Train Epoch: 4 [20800/42000 (50%)]\tLoss: 0.001882\n",
      "Train Epoch: 4 [22400/42000 (53%)]\tLoss: 0.003121\n",
      "Train Epoch: 4 [24000/42000 (57%)]\tLoss: 0.001879\n",
      "Train Epoch: 4 [25600/42000 (61%)]\tLoss: 0.005317\n",
      "Train Epoch: 4 [27200/42000 (65%)]\tLoss: 0.215378\n",
      "Train Epoch: 4 [28800/42000 (69%)]\tLoss: 0.001406\n",
      "Train Epoch: 4 [30400/42000 (72%)]\tLoss: 0.004077\n",
      "Train Epoch: 4 [32000/42000 (76%)]\tLoss: 0.002126\n",
      "Train Epoch: 4 [33600/42000 (80%)]\tLoss: 0.022330\n",
      "Train Epoch: 4 [35200/42000 (84%)]\tLoss: 0.003552\n",
      "Train Epoch: 4 [36800/42000 (88%)]\tLoss: 0.005982\n",
      "Train Epoch: 4 [38400/42000 (91%)]\tLoss: 0.177233\n",
      "Train Epoch: 4 [40000/42000 (95%)]\tLoss: 0.000082\n",
      "Train Epoch: 4 [41600/42000 (99%)]\tLoss: 0.001062\n",
      "Train Epoch: 5 [1600/42000 (4%)]\tLoss: 0.003938\n",
      "Train Epoch: 5 [3200/42000 (8%)]\tLoss: 0.009146\n",
      "Train Epoch: 5 [4800/42000 (11%)]\tLoss: 0.108065\n",
      "Train Epoch: 5 [6400/42000 (15%)]\tLoss: 0.017618\n",
      "Train Epoch: 5 [8000/42000 (19%)]\tLoss: 0.036870\n",
      "Train Epoch: 5 [9600/42000 (23%)]\tLoss: 0.000382\n",
      "Train Epoch: 5 [11200/42000 (27%)]\tLoss: 0.000095\n",
      "Train Epoch: 5 [12800/42000 (30%)]\tLoss: 0.000991\n",
      "Train Epoch: 5 [14400/42000 (34%)]\tLoss: 0.000730\n",
      "Train Epoch: 5 [16000/42000 (38%)]\tLoss: 0.002266\n",
      "Train Epoch: 5 [17600/42000 (42%)]\tLoss: 0.024241\n",
      "Train Epoch: 5 [19200/42000 (46%)]\tLoss: 0.132410\n",
      "Train Epoch: 5 [20800/42000 (50%)]\tLoss: 0.004682\n",
      "Train Epoch: 5 [22400/42000 (53%)]\tLoss: 0.002851\n",
      "Train Epoch: 5 [24000/42000 (57%)]\tLoss: 0.000145\n",
      "Train Epoch: 5 [25600/42000 (61%)]\tLoss: 0.000904\n",
      "Train Epoch: 5 [27200/42000 (65%)]\tLoss: 0.003567\n",
      "Train Epoch: 5 [28800/42000 (69%)]\tLoss: 0.004267\n",
      "Train Epoch: 5 [30400/42000 (72%)]\tLoss: 0.002572\n",
      "Train Epoch: 5 [32000/42000 (76%)]\tLoss: 0.000961\n",
      "Train Epoch: 5 [33600/42000 (80%)]\tLoss: 0.083464\n",
      "Train Epoch: 5 [35200/42000 (84%)]\tLoss: 0.098845\n",
      "Train Epoch: 5 [36800/42000 (88%)]\tLoss: 0.015863\n",
      "Train Epoch: 5 [38400/42000 (91%)]\tLoss: 0.000670\n",
      "Train Epoch: 5 [40000/42000 (95%)]\tLoss: 0.002737\n",
      "Train Epoch: 5 [41600/42000 (99%)]\tLoss: 0.278614\n",
      "Train Epoch: 6 [1600/42000 (4%)]\tLoss: 0.000065\n",
      "Train Epoch: 6 [3200/42000 (8%)]\tLoss: 0.033656\n",
      "Train Epoch: 6 [4800/42000 (11%)]\tLoss: 0.002839\n",
      "Train Epoch: 6 [6400/42000 (15%)]\tLoss: 0.000159\n",
      "Train Epoch: 6 [8000/42000 (19%)]\tLoss: 0.001817\n",
      "Train Epoch: 6 [9600/42000 (23%)]\tLoss: 0.000836\n",
      "Train Epoch: 6 [11200/42000 (27%)]\tLoss: 0.013767\n",
      "Train Epoch: 6 [12800/42000 (30%)]\tLoss: 0.000700\n",
      "Train Epoch: 6 [14400/42000 (34%)]\tLoss: 0.000685\n",
      "Train Epoch: 6 [16000/42000 (38%)]\tLoss: 0.008012\n",
      "Train Epoch: 6 [17600/42000 (42%)]\tLoss: 0.004012\n",
      "Train Epoch: 6 [19200/42000 (46%)]\tLoss: 0.000485\n",
      "Train Epoch: 6 [20800/42000 (50%)]\tLoss: 0.018275\n",
      "Train Epoch: 6 [22400/42000 (53%)]\tLoss: 0.008710\n",
      "Train Epoch: 6 [24000/42000 (57%)]\tLoss: 0.004739\n",
      "Train Epoch: 6 [25600/42000 (61%)]\tLoss: 0.007134\n",
      "Train Epoch: 6 [27200/42000 (65%)]\tLoss: 0.000659\n",
      "Train Epoch: 6 [28800/42000 (69%)]\tLoss: 0.014001\n",
      "Train Epoch: 6 [30400/42000 (72%)]\tLoss: 0.000158\n",
      "Train Epoch: 6 [32000/42000 (76%)]\tLoss: 0.039201\n",
      "Train Epoch: 6 [33600/42000 (80%)]\tLoss: 0.002296\n",
      "Train Epoch: 6 [35200/42000 (84%)]\tLoss: 0.001618\n",
      "Train Epoch: 6 [36800/42000 (88%)]\tLoss: 0.001439\n",
      "Train Epoch: 6 [38400/42000 (91%)]\tLoss: 0.000822\n",
      "Train Epoch: 6 [40000/42000 (95%)]\tLoss: 0.090437\n",
      "Train Epoch: 6 [41600/42000 (99%)]\tLoss: 0.011037\n",
      "Train Epoch: 7 [1600/42000 (4%)]\tLoss: 0.002603\n",
      "Train Epoch: 7 [3200/42000 (8%)]\tLoss: 0.000899\n",
      "Train Epoch: 7 [4800/42000 (11%)]\tLoss: 0.005107\n",
      "Train Epoch: 7 [6400/42000 (15%)]\tLoss: 0.034774\n",
      "Train Epoch: 7 [8000/42000 (19%)]\tLoss: 0.002500\n",
      "Train Epoch: 7 [9600/42000 (23%)]\tLoss: 0.000428\n",
      "Train Epoch: 7 [11200/42000 (27%)]\tLoss: 0.001840\n",
      "Train Epoch: 7 [12800/42000 (30%)]\tLoss: 0.010251\n",
      "Train Epoch: 7 [14400/42000 (34%)]\tLoss: 0.000669\n",
      "Train Epoch: 7 [16000/42000 (38%)]\tLoss: 0.003106\n",
      "Train Epoch: 7 [17600/42000 (42%)]\tLoss: 0.003929\n",
      "Train Epoch: 7 [19200/42000 (46%)]\tLoss: 0.188362\n",
      "Train Epoch: 7 [20800/42000 (50%)]\tLoss: 0.037191\n",
      "Train Epoch: 7 [22400/42000 (53%)]\tLoss: 0.063864\n",
      "Train Epoch: 7 [24000/42000 (57%)]\tLoss: 0.011203\n",
      "Train Epoch: 7 [25600/42000 (61%)]\tLoss: 0.006703\n",
      "Train Epoch: 7 [27200/42000 (65%)]\tLoss: 0.046470\n",
      "Train Epoch: 7 [28800/42000 (69%)]\tLoss: 0.012452\n",
      "Train Epoch: 7 [30400/42000 (72%)]\tLoss: 0.006547\n",
      "Train Epoch: 7 [32000/42000 (76%)]\tLoss: 0.012987\n",
      "Train Epoch: 7 [33600/42000 (80%)]\tLoss: 0.000404\n",
      "Train Epoch: 7 [35200/42000 (84%)]\tLoss: 0.004336\n",
      "Train Epoch: 7 [36800/42000 (88%)]\tLoss: 0.000594\n",
      "Train Epoch: 7 [38400/42000 (91%)]\tLoss: 0.001278\n",
      "Train Epoch: 7 [40000/42000 (95%)]\tLoss: 0.011202\n",
      "Train Epoch: 7 [41600/42000 (99%)]\tLoss: 0.011131\n",
      "Train Epoch: 8 [1600/42000 (4%)]\tLoss: 0.001177\n",
      "Train Epoch: 8 [3200/42000 (8%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [4800/42000 (11%)]\tLoss: 0.002598\n",
      "Train Epoch: 8 [6400/42000 (15%)]\tLoss: 0.000384\n",
      "Train Epoch: 8 [8000/42000 (19%)]\tLoss: 0.041803\n",
      "Train Epoch: 8 [9600/42000 (23%)]\tLoss: 0.001947\n",
      "Train Epoch: 8 [11200/42000 (27%)]\tLoss: 0.025466\n",
      "Train Epoch: 8 [12800/42000 (30%)]\tLoss: 0.000199\n",
      "Train Epoch: 8 [14400/42000 (34%)]\tLoss: 0.003175\n",
      "Train Epoch: 8 [16000/42000 (38%)]\tLoss: 0.003404\n",
      "Train Epoch: 8 [17600/42000 (42%)]\tLoss: 0.000517\n",
      "Train Epoch: 8 [19200/42000 (46%)]\tLoss: 0.000160\n",
      "Train Epoch: 8 [20800/42000 (50%)]\tLoss: 0.052843\n",
      "Train Epoch: 8 [22400/42000 (53%)]\tLoss: 0.003344\n",
      "Train Epoch: 8 [24000/42000 (57%)]\tLoss: 0.001782\n",
      "Train Epoch: 8 [25600/42000 (61%)]\tLoss: 0.003655\n",
      "Train Epoch: 8 [27200/42000 (65%)]\tLoss: 0.029042\n",
      "Train Epoch: 8 [28800/42000 (69%)]\tLoss: 0.000825\n",
      "Train Epoch: 8 [30400/42000 (72%)]\tLoss: 0.145337\n",
      "Train Epoch: 8 [32000/42000 (76%)]\tLoss: 0.000106\n",
      "Train Epoch: 8 [33600/42000 (80%)]\tLoss: 0.003506\n",
      "Train Epoch: 8 [35200/42000 (84%)]\tLoss: 0.013455\n",
      "Train Epoch: 8 [36800/42000 (88%)]\tLoss: 0.000039\n",
      "Train Epoch: 8 [38400/42000 (91%)]\tLoss: 0.004321\n",
      "Train Epoch: 8 [40000/42000 (95%)]\tLoss: 0.000396\n",
      "Train Epoch: 8 [41600/42000 (99%)]\tLoss: 0.002303\n",
      "Train Epoch: 9 [1600/42000 (4%)]\tLoss: 0.007576\n",
      "Train Epoch: 9 [3200/42000 (8%)]\tLoss: 0.000055\n",
      "Train Epoch: 9 [4800/42000 (11%)]\tLoss: 0.010766\n",
      "Train Epoch: 9 [6400/42000 (15%)]\tLoss: 0.001468\n",
      "Train Epoch: 9 [8000/42000 (19%)]\tLoss: 0.002830\n",
      "Train Epoch: 9 [9600/42000 (23%)]\tLoss: 0.000083\n",
      "Train Epoch: 9 [11200/42000 (27%)]\tLoss: 0.416839\n",
      "Train Epoch: 9 [12800/42000 (30%)]\tLoss: 0.001043\n",
      "Train Epoch: 9 [14400/42000 (34%)]\tLoss: 0.000153\n",
      "Train Epoch: 9 [16000/42000 (38%)]\tLoss: 0.001101\n",
      "Train Epoch: 9 [17600/42000 (42%)]\tLoss: 0.035514\n",
      "Train Epoch: 9 [19200/42000 (46%)]\tLoss: 0.000132\n",
      "Train Epoch: 9 [20800/42000 (50%)]\tLoss: 0.055759\n",
      "Train Epoch: 9 [22400/42000 (53%)]\tLoss: 0.007499\n",
      "Train Epoch: 9 [24000/42000 (57%)]\tLoss: 0.000153\n",
      "Train Epoch: 9 [25600/42000 (61%)]\tLoss: 0.000984\n",
      "Train Epoch: 9 [27200/42000 (65%)]\tLoss: 0.002626\n",
      "Train Epoch: 9 [28800/42000 (69%)]\tLoss: 0.004667\n",
      "Train Epoch: 9 [30400/42000 (72%)]\tLoss: 0.003634\n",
      "Train Epoch: 9 [32000/42000 (76%)]\tLoss: 0.024289\n",
      "Train Epoch: 9 [33600/42000 (80%)]\tLoss: 0.000017\n",
      "Train Epoch: 9 [35200/42000 (84%)]\tLoss: 0.001128\n",
      "Train Epoch: 9 [36800/42000 (88%)]\tLoss: 0.010803\n",
      "Train Epoch: 9 [38400/42000 (91%)]\tLoss: 0.061809\n",
      "Train Epoch: 9 [40000/42000 (95%)]\tLoss: 0.004839\n",
      "Train Epoch: 9 [41600/42000 (99%)]\tLoss: 0.003889\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    net.train()\n",
    "    for batch_id, (im, target) in enumerate(train_loader):\n",
    "    \n",
    "        im = im.to('cuda')\n",
    "        target = target.to('cuda')\n",
    "        opt.zero_grad()\n",
    "        pred = net(im)\n",
    "        l = loss(pred, target)\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        if (batch_id + 1)% 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_id + 1) * len(im), len(train_loader.dataset),\n",
    "                100. * (batch_id + 1) / len(train_loader), l.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor(pd.read_csv(\"test.csv\").values)/255.0\n",
    "test = test.reshape(28000, 28, 28).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for im in range(28000):\n",
    "    \n",
    "    out = net(test[None, im]).data.max(1, keepdim=True)[1]\n",
    "    a.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(a)\n",
    "a = a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame({\"ImageId\": range(1, 28001), \"Label\": a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}